#better version

from obspy import read
from obspy import UTCDateTime
import pandas as pd
from pathlib import Path
import numpy as np
from scipy.signal import find_peaks
import matplotlib.pyplot as plt

# Load the pick data
pick_data = pd.read_csv(
    "dataset_earthquakes/metadata.csv",
    usecols=['trace_name_original_1', 'trace_p_pick_time', 'trace_s_pick_time', 'source_sensor_distance']
)

def sanitize_filename(name):
    """Sanitize file names for consistent matching"""
    return str(name).replace(".", "").replace(":", "").replace("-", "").replace("_", "").strip().lower()

def calculate_snr(trace, time_point, pre_window=2, post_window=2):
    """
    Calculate SNR for a specific time point using pre and post windows
    """
    sampling_rate = trace.stats.sampling_rate
    
    # Convert time point to sample index
    point_index = int((time_point - trace.stats.starttime) * sampling_rate)
    
    # Calculate window indices
    noise_start = max(0, point_index - int(pre_window * sampling_rate))
    noise_end = point_index
    signal_start = point_index
    signal_end = min(len(trace.data), point_index + int(post_window * sampling_rate))
    
    # Extract windows
    noise_window = trace.data[noise_start:noise_end]
    signal_window = trace.data[signal_start:signal_end]
    
    # Calculate RMS values
    noise_rms = np.sqrt(np.mean(noise_window**2)) if len(noise_window) > 0 else 1e-10
    signal_rms = np.sqrt(np.mean(signal_window**2)) if len(signal_window) > 0 else 0
    
    return signal_rms / noise_rms

def calculate_snr_series(trace, pre_window=2, post_window=2):
    """
    Calculate SNR for entire trace using sliding windows
    """
    sampling_rate = trace.stats.sampling_rate
    window_samples = int((pre_window + post_window) * sampling_rate)
    
    # Calculate SNR at fewer points to improve performance
    step = max(1, int(sampling_rate / 10))  # Calculate SNR every 0.1 seconds
    times = []
    snr_values = []
    
    for i in range(0, len(trace.data) - window_samples, step):
        current_time = trace.stats.starttime + i/sampling_rate
        snr = calculate_snr(trace, current_time, pre_window, post_window)
        times.append(current_time)
        snr_values.append(snr)
    
    return np.array(times), np.array(snr_values)

def find_snr_peaks(times, snr_values, min_snr=2.0, min_distance_samples=10):
    """Find peaks in SNR values above threshold"""
    if len(snr_values) == 0:
        return np.array([]), np.array([])
    
    peaks, properties = find_peaks(snr_values, height=min_snr, distance=min_distance_samples)
    if len(peaks) == 0:
        return np.array([]), np.array([])
    
    return times[peaks], snr_values[peaks]

def validate_p_picks(trace, p_pick_time, time_tolerance=1.0, snr_threshold=2.0):
    """
    Validate P-picks by comparing with SNR peaks
    """
    # Calculate SNR series
    times, snr_values = calculate_snr_series(trace)
    
    # Find SNR peaks
    peak_times, peak_snrs = find_snr_peaks(times, snr_values, snr_threshold)
    
    # Calculate SNR at P-pick time
    p_pick_snr = calculate_snr(trace, p_pick_time)
    
    # Find nearest peak to P-pick
    if len(peak_times) > 0:
        time_diffs = np.abs([t.timestamp - p_pick_time.timestamp for t in peak_times])
        nearest_peak_idx = np.argmin(time_diffs)
        nearest_peak_time = peak_times[nearest_peak_idx]
        nearest_peak_snr = peak_snrs[nearest_peak_idx]
        
        # Check if within tolerance
        is_valid = time_diffs[nearest_peak_idx] <= time_tolerance
    else:
        is_valid = False
        nearest_peak_time = None
        nearest_peak_snr = None
    
    return is_valid, p_pick_snr, nearest_peak_time, nearest_peak_snr, times, snr_values, peak_times, peak_snrs

def plot_validation_results(trace, p_pick_time, times, snr_values, peak_times, peak_snrs, save_path):
    """Plot trace data, SNR values, and validation results"""
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))
    
    # Plot trace data
    trace_times = np.arange(len(trace.data)) / trace.stats.sampling_rate
    ax1.plot(trace_times, trace.data, 'b-', label='Trace Data')
    ax1.axvline(p_pick_time - trace.stats.starttime, color='r', linestyle='--', label='P-Pick')
    ax1.set_title('Seismic Trace')
    ax1.legend()
    
    # Plot SNR values
    if len(times) > 0:
        ax2.plot(times - trace.stats.starttime, snr_values, 'g-', label='SNR')
        if len(peak_times) > 0:
            ax2.scatter(peak_times - trace.stats.starttime, peak_snrs, color='r', label='SNR Peaks')
    ax2.axvline(p_pick_time - trace.stats.starttime, color='r', linestyle='--', label='P-Pick')
    ax2.axhline(2.0, color='k', linestyle=':', label='SNR Threshold')
    ax2.set_title('Signal-to-Noise Ratio')
    ax2.legend()
    
    plt.tight_layout()
    plt.savefig(save_path)
    plt.close()

# Main processing loop
mseed_dir = "miniSEED_files"
results = []

# Statistics counters
total_files = 0
files_with_metadata = 0
processed_traces = 0
correctly_matched = 0
incorrectly_matched = 0
failed_processing = 0
no_peaks_found = 0

print("Starting processing...")

for file_path in Path(mseed_dir).glob("*.MSEED"):
    total_files += 1
    mseed_name = sanitize_filename(file_path.name)
    print(f"\nProcessing file: {file_path.name}")
    
    # Find matching metadata
    matched_rows = pick_data[pick_data['trace_name_original_1'].apply(sanitize_filename) == mseed_name]
    
    if len(matched_rows) == 0:
        print(f"No metadata match found for: {file_path.name}")
        continue
    
    files_with_metadata += 1
    matched_row = matched_rows.iloc[0]
    
    try:
        p_pick = UTCDateTime(matched_row['trace_p_pick_time'])
        stream = read(file_path)
        
        for trace in stream:
            processed_traces += 1
            print(f"Processing trace: {trace.id}")
            
            # Validate P-pick
            try:
                is_valid, p_pick_snr, nearest_peak_time, nearest_peak_snr, times, snr_values, peak_times, peak_snrs = validate_p_picks(trace, p_pick)
                
                if len(peak_times) == 0:
                    no_peaks_found += 1
                    print(f"No SNR peaks found above threshold for {trace.id}")
                
                if is_valid:
                    correctly_matched += 1
                    match_status = "CORRECT"
                else:
                    incorrectly_matched += 1
                    match_status = "INCORRECT"
                
                # Plot results
                plot_path = f"validation_{trace.id}_{match_status}.png"
                plot_validation_results(trace, p_pick, times, snr_values, peak_times, peak_snrs, plot_path)
                
                # Store results
                time_diff = None if nearest_peak_time is None else abs(nearest_peak_time - p_pick)
                results.append({
                    'trace_id': trace.id,
                    'file_name': file_path.name,
                    'is_valid': is_valid,
                    'p_pick_snr': p_pick_snr,
                    'nearest_peak_time': nearest_peak_time,
                    'nearest_peak_snr': nearest_peak_snr,
                    'time_difference': time_diff
                })
                
            except Exception as e:
                failed_processing += 1
                print(f"Error processing trace {trace.id}: {e}")
                
    except Exception as e:
        failed_processing += 1
        print(f"Error processing file {file_path.name}: {e}")

# Create summary DataFrame
results_df = pd.DataFrame(results)

# Print comprehensive statistics
print("\n=== Processing Statistics ===")
print(f"Total files found: {total_files}")
print(f"Files with matching metadata: {files_with_metadata}")
print(f"Total traces processed: {processed_traces}")
print(f"Correctly matched P-picks: {correctly_matched}")
print(f"Incorrectly matched P-picks: {incorrectly_matched}")
print(f"Traces with no peaks found: {no_peaks_found}")
print(f"Failed processing: {failed_processing}")

if len(results_df) > 0:
    print("\n=== Match Quality Statistics ===")
    print(f"Average P-pick SNR: {results_df['p_pick_snr'].mean():.2f}")
    valid_diffs = results_df[results_df['time_difference'].notna()]['time_difference']
    if len(valid_diffs) > 0:
        print(f"Average time difference for matches: {valid_diffs.mean():.3f} seconds")
        print(f"Max time difference for matches: {valid_diffs.max():.3f} seconds")

# Save results to CSV
results_df.to_csv("p_pick_validation_results.csv", index=False)
print("\nResults saved to p_pick_validation_results.csv")
