{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:26: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:26: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\Ayush_trainee\\AppData\\Local\\Temp\\ipykernel_5412\\630651975.py:26: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  json_file_path = \"AWS EARTHQUAKE DATASET\\date=2018-01-19time=16-17-45/001/15.jsonl\"\n",
      "C:\\Users\\Ayush_trainee\\AppData\\Local\\Temp\\ipykernel_5412\\630651975.py:26: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  json_file_path = \"AWS EARTHQUAKE DATASET\\date=2018-01-19time=16-17-45/001/15.jsonl\"\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'AWS EARTHQUAKE DATASET\\\\date=2018-01-19time=16-17-45/001/15.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 122\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m# Run the function\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m result_df \u001b[38;5;241m=\u001b[39m process_json(json_file_path)\n\u001b[0;32m    123\u001b[0m result_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle_json_prediction.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing complete, results saved!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 29\u001b[0m, in \u001b[0;36mprocess_json\u001b[1;34m(json_file)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_json\u001b[39m(json_file):\n\u001b[1;32m---> 29\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(json_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m file:\n\u001b[0;32m     31\u001b[0m             record \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(line)\n",
      "File \u001b[1;32mc:\\Users\\Ayush_trainee\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'AWS EARTHQUAKE DATASET\\\\date=2018-01-19time=16-17-45/001/15.jsonl'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew, kurtosis, mode, zscore\n",
    "from datetime import datetime, timedelta\n",
    "from obspy.signal.trigger import classic_sta_lta\n",
    "\n",
    "def compute_mer(signal, window_size=50):\n",
    "    energy = np.convolve(signal**2, np.ones(window_size), mode='valid')\n",
    "    mer = np.zeros(len(signal))\n",
    "    mer[window_size - 1: window_size - 1 + len(energy)] = energy\n",
    "    return mer\n",
    "\n",
    "# Load the trained model and scaler\n",
    "model_path = \"sgd_classifier_model_updated.pkl\"\n",
    "scaler_path = \"scaler_updated.pkl\"\n",
    "with open(model_path, 'rb') as model_file:\n",
    "    model = pickle.load(model_file)\n",
    "with open(scaler_path, 'rb') as scaler_file:\n",
    "    scaler = pickle.load(scaler_file)\n",
    "\n",
    "# Define JSON file path\n",
    "json_file_path = \"AWS EARTHQUAKE DATASET\\date=2018-01-19time=16-17-45/001/15.jsonl\"\n",
    "\n",
    "def process_json(json_file):\n",
    "    with open(json_file, \"r\") as file:\n",
    "        for line in file:\n",
    "            record = json.loads(line)\n",
    "            device_time = datetime.utcfromtimestamp(record[\"device_t\"])\n",
    "            sr = record[\"sr\"]\n",
    "            \n",
    "            duration = len(record[\"x\"]) / sr\n",
    "            time_values = [\n",
    "                (device_time + timedelta(seconds=(i / sr))).strftime('%H:%M:%S.%f')[:-3] \n",
    "                for i in range(len(record[\"x\"]))\n",
    "            ]\n",
    "            \n",
    "            x_data = np.array(record[\"x\"])\n",
    "            time_data = np.array(time_values)\n",
    "    \n",
    "    # Compute STA/LTA and MER\n",
    "    sta_window = int(1 * sr)\n",
    "    lta_window = int(10 * sr)\n",
    "    sta_lta_x = classic_sta_lta(x_data, sta_window, lta_window)\n",
    "    mer_x = compute_mer(x_data, window_size=50)\n",
    "    \n",
    "    before_duration = int(1 * sr)\n",
    "    after_duration = int(0.5 * sr)\n",
    "    step_size = int(0.5 * sr)\n",
    "    window_size = before_duration + after_duration\n",
    "    \n",
    "    data_records = []\n",
    "    window_index = 1\n",
    "    start_idx = 0\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    while start_idx + window_size <= len(x_data):\n",
    "        window_start_time = time_data[start_idx]\n",
    "        \n",
    "        before_data = x_data[start_idx:start_idx + before_duration]\n",
    "        after_data = x_data[start_idx + before_duration:start_idx + window_size]\n",
    "        before_sta_lta = sta_lta_x[start_idx:start_idx + before_duration]\n",
    "        after_sta_lta = sta_lta_x[start_idx + before_duration:start_idx + window_size]\n",
    "        before_mer = mer_x[start_idx:start_idx + before_duration]\n",
    "        after_mer = mer_x[start_idx + before_duration:start_idx + window_size]\n",
    "        \n",
    "        def compute_stats(data, sta_lta, mer):\n",
    "            if len(data) == 0:\n",
    "                return [np.nan] * 13\n",
    "            mode_value = mode(data, keepdims=True)[0]\n",
    "            return [\n",
    "                np.mean(data), np.median(data), mode_value[0] if mode_value.size > 0 else np.nan, np.std(data),\n",
    "                skew(data), kurtosis(data), np.var(data), np.max(data), np.min(data),\n",
    "                np.mean(zscore(data)), np.mean(sta_lta), np.max(sta_lta),\n",
    "                np.mean(mer), np.max(mer)\n",
    "            ]\n",
    "        \n",
    "        before_stats = compute_stats(before_data, before_sta_lta, before_mer)\n",
    "        after_stats = compute_stats(after_data, after_sta_lta, after_mer)\n",
    "        \n",
    "        feature_vector = np.array(before_stats + after_stats).reshape(1, -1)\n",
    "        scaled_features = scaler.transform(feature_vector)\n",
    "        predicted_label = model.predict(scaled_features)[0]\n",
    "        \n",
    "        predictions.append((window_index, start_idx, predicted_label, window_start_time))\n",
    "        data_records.append([window_index, window_start_time] + before_stats + after_stats + [predicted_label])\n",
    "        \n",
    "        window_index += 1\n",
    "        start_idx += step_size\n",
    "    \n",
    "    df = pd.DataFrame(data_records, columns=[\n",
    "        \"Window Index\", \"Window Start Time\", \"Before Mean\", \"Before Median\", \"Before Mode\", \"Before Std Dev\", \n",
    "        \"Before Skewness\", \"Before Kurtosis\", \"Before Variance\", \"Before Max\", \"Before Min\", \"Before Z-Score\", \n",
    "        \"Before Mean STA/LTA\", \"Before Max STA/LTA\", \"Before Mean MER\", \"Before Max MER\", \n",
    "        \"After Mean\", \"After Median\", \"After Mode\", \"After Std Dev\", \"After Skewness\", \n",
    "        \"After Kurtosis\", \"After Variance\", \"After Max\", \"After Min\", \"After Z-Score\", \n",
    "        \"After Mean STA/LTA\", \"After Max STA/LTA\", \"After Mean MER\", \"After Max MER\", \"Predicted Label\"\n",
    "    ])\n",
    "    \n",
    "    # Plot results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(time_data, x_data, label='Waveform', color='gray')\n",
    "    \n",
    "    for win_idx, start_idx, label, start_time in predictions:\n",
    "        if label == 1:\n",
    "            plt.axvspan(time_data[start_idx], time_data[start_idx + window_size], color='red', alpha=0.3, label=f'Window {win_idx}')\n",
    "            plt.text(time_data[start_idx], np.max(x_data), f'W{win_idx}\\n{start_time}', color='black', fontsize=8, verticalalignment='top')\n",
    "    \n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.title('Seismic Waveform with Predicted Event Windows')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Run the function\n",
    "result_df = process_json(json_file_path)\n",
    "result_df.to_csv(\"single_json_prediction.csv\", index=False)\n",
    "print(\"Processing complete, results saved!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
